# Language Models as Cultural Mirrors:
## Can LLMs Authentically Simulate Global Value Orientations?
This repository supports the research project _"Language Models as Cultural Mirrors: Can LLMs Authentically Simulate Global Value Orientations", which investigates whether large language models (LLMs) reflect and simulate global cultural value orientations. By leveraging established frameworks (GLOBE), we evaluate the extent to which models (GPT-4, GPT-4o, Mistral, and Yi) align with or deviate from the cultural alignment in France, China, the United States, the United Kingdom, and average English Speaking Country.


## Folder Structure

### Data
Contains raw and processed datasets used for cultural value assessments, including model responses, country benchmarks from GLOBE, and model metadata.

### Code
Includes Google Colab code for data cleaning, analysis, model querying, scoring mechanisms, and cultural alignment evaluations.

### Questionnaires and Prompts
Stores the standardized value orientation surveys and prompt templates used to elicit responses from different LLMs, aligned with GLOBE dimensions.
